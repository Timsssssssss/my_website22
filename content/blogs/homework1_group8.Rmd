---
categories:  
- ""    #the front matter should be like the one found in, e.g., blog2.md. It cannot be like the normal Rmd we used
- ""
date: "2022-09-04"
description: My LBS Statistics Ptoject using R # the title that will show up once someone gets to this page
draft: false
image: data.jpg # save picture in \static\img\blogs. Acceptable formats= jpg, jpeg, or png . Your iPhone pics wont work

keywords: ""
slug: proj1 # slug is the shorthand URL address... no spaces plz
title: Application of dplyr in R
---

```{r, setup, echo=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,     # display code as typed
  size="small")   # slightly smaller font for code
options(digits = 3)

knitr::opts_chunk$set(
  fig.width=8, 
  fig.height=6,
  fig.align = "center"
)
```

```{r load-libraries, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(vroom)
library(tidyquant)
library(dplyr)
library(ggplot2)
```

# Rents in San Francsisco 2000-2018

```{r}
# download directly off tidytuesdaygithub repo

rent <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-07-05/rent.csv')

```

The data is separated into both characters and numbers. At first look, the data types seem to be correctly allocated given the nature of the variables. As for completeness, the most missing value is the description with 197,542 missing. However, details and location (address and coordinates) are closely behind. This is not very surprising, as people are both careful with publishing addresses on craigslist and lazy in writing detailed descriptions.

```{r skim_rents_data}
# Inspect the rent data
skimr::skim(rent)

```

Make a plot that shows the top 20 cities in terms of % of classifieds between 2000-2018. You need to calculate the number of listings by city, and then convert that number to a %.


```{r plot_top_cities}
# Group by city and count
rent %>%
  group_by(city) %>% 
  count() %>% 
  # count the rows with in a group and returns a new column n
  ungroup %>% 
  mutate(pct_city = n/sum(n)) %>% 
  # divided each group's number of rentals by the total amount(sum of all groups)
  slice_max(order_by=pct_city, n=20) %>% 
  ggplot(aes(x=pct_city,y=fct_reorder(city,pct_city))) + 
    geom_col()+
    labs(title="San Francisco accounts for more than a quarter of all rental classifieds",subtitle ="% of Craigslist listings, 2000-2018",x=NULL,y=NULL,caption = "Source: Pennington, Kate (2018). Bay Area Craigslist Rental Housing Posts,2010-2018")+
    theme_bw()+
    theme(panel.border = element_blank()) +
    theme(plot.title.position = "plot")+
    scale_x_continuous(labels = scales::percent) #Transform the x-axis label into percentage
```

Make a plot that shows the evolution of median prices in San Francisco for 0, 1, 2, and 3 bedrooms listings.

```{r sf_median_prices}

rent %>% 
  filter(city=="san francisco", beds %in% 0:3) %>% 
  group_by(beds,year) %>%
  summarize(median_price=median(price)) %>% 
  ggplot(aes(x=year,y=median_price,colour=factor(beds)))+
  geom_line()+
  labs(title="San Francisco rents have been steadily increasing",subtitle = "0 to 3-bed listings,  2000-2018",x=NULL,y=NULL,caption = "Source: Pennington, Kate (2018). Bay Area Craigslist Rental Housing Posts,2010-2018")+
  facet_wrap(~beds,nrow=1)+ #facet beds
  theme_bw()+ # change the theme as black-white
  theme(plot.title.position = "plot")+
  theme(legend.position = "none")+ # hide the legends
  scale_color_manual(values = c("red","green","blue","purple"))

```

Finally, make a plot that shows median rental prices for the top 12 cities in the Bay area.

```{r spirit_plot}
# find the top 12 cities 
top_cities = rent %>%
  group_by(city) %>% 
  count() %>% 
  ungroup %>% 
  mutate(percent = n/sum(n)) %>% 
  slice_max(order_by=percent, n=12)

rent %>% 
  filter(beds==1,  
         city %in%  top_cities$city) %>% #filter out the cities with 1 bed 
  group_by(city,year) %>% 
  summarize(median_price=median(price)) %>% 
  ggplot(aes(x=year,y=median_price,colour=city))+
  geom_line()+
  facet_wrap(~city,nrow=3)+
  theme_bw()+
  theme(plot.title.position = "plot")+
  labs(title="Rental prices for 1-bedroom flats in the Bay Area",x=NULL,y=NULL,caption = "Source: Pennington, Kate (2018). Bay Area Craigslist Rental Housing Posts, 2010-2018")+
  theme(legend.position = "none")# hide the legend
```

First of all, San Francisco has the most listings among all the cities it the Bay Area. The reason behind this could be that San Francisco has a booming economy and is a popular location for large companies, such as Uber or Twitter. These companies recruit a lot outside of San Francisco, leading to a large influx in individuals requiring local accommodation. As the demand is high, supply follows suit. Smaller towns like Redwood City have low population and don't draw nearly as many foreign settlers. Therefore, the number of listings is comparatively lower.

The increase in rental prices between 2000 and 2018 in San Francisco is proportionally approximately the same between 0 to 3 bed listings. If there was a larger increase in families over that time frame, we could potentially see prices for 2 and 3 bedroom flats ascending more extremely given the increase demand. However, the demand seems to be equally balanced between all sizes. We should also not be surprised to see generally higher prices in San Francisco compared to other cities in the Bay Area. This is most likely a result of the popularity of the city for foreigners and the limited space available for additional housing, among others. By observing the price line charts for all cities in the Bay Area, we can see that all have experienced a rise in prices between 2000 and 2018. A natural increase over time is to be expected, given inflation. However we see more pronounced increases in some areas versus others, the reasons for which could be further investigated. An example would be Palo Alto, which is of course known for the Stanford Campus. Last but not least, the dip in 2008/2009 is worth mentioning. This is most likely a result of the financial crisis during that time. The difference in the gravity of the dip between cities provides some intriguing insights.

# Analysis of movies- IMDB dataset

```{r,load_movies, warning=FALSE, message=FALSE}
# Assign IMDB data to variable
movies <- read_csv(here::here("data", "movies.csv"))

```

## Use your data import, inspection, and cleaning skills to answer the following:

-   Are there any missing values (NAs)? Are all entries distinct or are there duplicate entries?

There are no missing values according to the skim function. Nevertheless, we notice some duplicate values, for example "Nightmare on Elm Street" or "Alice in Wonderland". We have to be careful to look at more than just the title in identifying duplicates, as some movies could have the same name, but be released twice on different dates or have a different director.

```{r,Skim_data}
# Skim IMDB data
skim(movies)

```

-   Produce a table with the count of movies by genre, ranked in descending order

    ```{r,count_of_movies}
    movies%>%
      count(sort = TRUE,genre)
    ```

-   Produce a table with the average gross earning and budget (`gross` and `budget`) by genre. Calculate a variable `return_on_budget` which shows how many \$ did a movie make at the box office for each \$ of its budget. Ranked genres by this `return_on_budget` in descending order

    ```{r,avg_gross_budget}
    # Create table with the average gross earning and budget
    avg_genre = movies%>%
      group_by(genre) %>% 
      summarize(avg_earning = sum(gross)/count(genre),
                avg_budget = sum(budget)/count(genre)) # Create 2 columns to store the average earning and budget
    avg_genre%>% 
      mutate(return_on_budget = avg_earning/avg_budget) %>% # The return is just the earning/budget
      arrange(desc(return_on_budget))
    ```

-   Produce a table that shows the top 15 directors who have created the highest gross revenue in the box office. Don't just show the total gross amount, but also the mean, median, and standard deviation per director.

    ```{r,top_15}
    # Calculate summary statistics for top 15 directors 
    Top_directors = movies%>%
      group_by(director) %>% 
      summarise(sum_gross = sum(gross),
                mean_gross = mean(gross),
                median_gross = median(gross),
                SD_gross = sd(gross))
    # Choose the top 15 with highest gross earnings
    Top_directors%>%
      slice_max(sum_gross,n = 15)
    ```

-   Finally, ratings. Produce a table that describes how ratings are distributed by genre. We don't want just the mean, but also, min, max, median, SD and some kind of a histogram or density graph that visually shows how ratings are distributed.

    ```{r,rating}
    # Calculate summary statistics for ratings by genre
    Ratings_genre = movies%>%
      group_by(genre)%>%
      summarise(mean_ratings = mean(rating),
                min_rating = min(rating),
                max_rating = max(rating),
                median_rating = median(rating),
                SD_rating = sd(rating))
    Ratings_genre

    # Plot ratings by genre
    ggplot(movies,aes(x=rating)) +
      geom_density() +
      labs(title="There are few completely unpopular movies with a rating of less than 5",subtitle = "Density plot of movie ratings on IMDB",x = "Rating", y = "Density")+
      theme_bw()
    ```

## Use `ggplot` to answer the following

-   Examine the relationship between `gross` and `cast_facebook_likes`. Produce a scatterplot and write one sentence discussing whether the number of facebook likes that the cast has received is likely to be a good predictor of how much money a movie will make at the box office. What variable are you going to map to the Y- and X- axes?

While there seems to be a minor correlation between the amount of cast facebook likes and the money a movie makes, the relationship is not strong enough to make it a good predictor of a movie's success.

```{r, gross_on_fblikes}
# Map revenue vs Facebook likes
movies%>%
ggplot(aes(x=cast_facebook_likes, y = gross)) +
  geom_point()+scale_x_log10()+geom_smooth(method = "lm", se = FALSE) +
  labs(title="Cast Facebook likes do not seem to be a reliable predictor of movie success",subtitle = "Scatterplot of number of cast facebook likes and movie gross revenue",x = "Number of Cast Facebook Likes", y = "Gross Revenue")+
  theme_bw()
```

-   Examine the relationship between `gross` and `budget`. Produce a scatterplot and write one sentence discussing whether budget is likely to be a good predictor of how much money a movie will make at the box office.

While a budget is surely not a guarantor of movie success , the fitted line has a positive slope and therefore implies that with rising budget comes rising gross revenue.

```{r, gross_on_budget}
 #Map revenue vs budget
movies%>%
  ggplot(aes(x=budget,y=gross))+
  geom_point()+geom_smooth(method = "lm", se = FALSE) +
  labs(title="A higher budget seems to positively affect movie gross revenue",subtitle = "Scatterplot of movie budget and movie gross revenue",x = "Budget", y = "Gross Revenue")+
  theme_bw()

```

-   Examine the relationship between `gross` and `rating`. Produce a scatterplot, faceted by `genre` and discuss whether IMDB ratings are likely to be a good predictor of how much money a movie will make at the box office. Is there anything strange in this dataset?

Generally, higher ratings indicates higher gross earnings for all genres for which we have a significant amount of data. However, we can also see that it is possible for movies to have a good rating while not making a lot of money. This most likely concern the likes of indie movies, that receive strong support but never make it into the pop culture.

There are some interesting anomalies in the data in the form of extreme values. Drama movies usually fall within the same range of gross revenues, however "Titanic" by James Cameron reports much higher values than the rest. Coincidentally, James Cameron is also the director for highest grossing movie in the data "Avatar". It is also noticeable that there are no observable outliers for genres like comedy or adventure, even though there are several movies of the genre in the data. Apparently these categories do not display the required parameters to polarize the nation.

```{r, gross_on_rating}
# Map revenue vs rating, faceted by genre
movies%>%
  ggplot(aes(x=rating, y = gross,color=genre))+
  geom_point()+facet_wrap(~genre)+
  labs(title="A higher rating seems to be correlated to higher gross revenues",subtitle = "Faceted scatterplot of IMDB rating and movie gross revenue",x = "IMDB Rating", y = "Gross Revenue")
```

# Returns of financial stocks

```{r load_nyse_data, message=FALSE, warning=FALSE}
nyse <- read_csv( here::here("data","nyse.csv"))
```

Based on this dataset, create a table and a bar plot that shows the number of companies per sector, in descending order

```{r companies_per_sector}
# Create table of companies per sector
num_persec <- nyse %>% 
  group_by(sector) %>% 
  summarize(num_com = count(sector)) #Group by sector and count
num_persec

# Plot companies per sector
ggplot(num_persec,aes(y = fct_reorder(sector,num_com),x = num_com)) +
  geom_col()+
  labs(title="Number of companies per sector", x="Number of Companies",
       x = NULL,
       y = NULL)+
  theme_bw()
```

Next, let's choose some stocks and their ticker symbols and download some data. You **MUST** choose 6 different stocks from the ones listed below; You should, however, add `SPY` which is the SP500 ETF (Exchange Traded Fund).

```{r get_price_data, message=FALSE, warning=FALSE, cache=TRUE}

# Collect stock prices of chosen stocks
myStocks <- c("AAPL","JPM","DIS","DPZ","ANF","TSLA","XOM","SPY" ) %>%
  tq_get(get  = "stock.prices",
         from = "2011-01-01",
         to   = "2022-08-31") %>%
  group_by(symbol) 

# Inspect data
glimpse(myStocks) # examine the structure of the resulting data frame
```

Financial performance analysis depend on returns; If I buy a stock today for 100 and I sell it tomorrow for 101.75, my one-day return, assuming no transaction costs, is 1.75%. So given the adjusted closing prices, our first step is to calculate daily and monthly returns.

```{r calculate_returns, message=FALSE, warning=FALSE, cache=TRUE}
#calculate daily returns
myStocks_returns_daily <- myStocks %>%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = "daily", 
               type       = "log",
               col_rename = "daily_returns",
               cols = c(nested.col))  

#calculate monthly  returns
myStocks_returns_monthly <- myStocks %>%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = "monthly", 
               type       = "arithmetic",
               col_rename = "monthly_returns",
               cols = c(nested.col)) 

#calculate yearly returns
myStocks_returns_annual <- myStocks %>%
  group_by(symbol) %>%
  tq_transmute(select     = adjusted, 
               mutate_fun = periodReturn, 
               period     = "yearly", 
               type       = "arithmetic",
               col_rename = "yearly_returns",
               cols = c(nested.col))
```

Create a table where you summarise monthly returns for each of the stocks and `SPY`; min, max, median, mean, SD.

```{r summarise_monthly_returns}

# Create summary table of stocks and calculate summary statistics
summary_stocks <- myStocks_returns_monthly %>% 
  group_by(symbol) %>% 
  summarize(min=min(monthly_returns),max=max(monthly_returns),median=median(monthly_returns),mean = mean(monthly_returns),sd = sd(monthly_returns))

```

Plot a density plot, using `geom_density()`, for each of the stocks

```{r density_monthly_returns}
# Create density plot for stocks
myStocks_returns_monthly %>% 
  ggplot(aes(x = monthly_returns,color = symbol))+geom_density() +
  labs(title="The stocks roughly follow a normal distribution, with varying standard deviations",subtitle = "Density plot of monthly stock returns per stock",x = "Monthly Returns", y = "Density")+
  theme_bw()
```

What can you infer from this plot? Which stock is the riskiest? The least risky?

> TYPE YOUR ANSWER AFTER (AND OUTSIDE!) THIS BLOCKQUOTE.

We can observe from the plot that all stocks roughly follow a normal distribution. ANF can be considered the riskiest stock, as it has the lowest mean with the highest standard deviation We can conclude that there is a higher variation in the returns, usually associated with increased risks. SPY can be considered the least risky stock, given the tall and slim shape of the curve. Additionally, the SPY is a fund to mirror the S&P 500 and therefore less risky in nature.

Finally, make a plot that shows the expected monthly return (mean) of a stock on the Y axis and the risk (standard deviation) in the X-axis. Please use `ggrepel::geom_text_repel()` to label each stock

```{r risk_return_plot}
# Create risk vs return scatterplot
library(ggrepel)
summary_stocks %>% 
  ggplot(aes(x=sd,y=mean,label = symbol))+geom_point()+geom_text_repel() +
  labs(title="The higher the risk one accepts, the higher the average return",subtitle = "Scatterplot of stock return standard deviation and average return",x = "Standard Deviation (Risk)", y = "Average Return")+
  theme_bw()
```

What can you infer from this plot? Are there any stocks which, while being riskier, do not have a higher expected return?

> TYPE YOUR ANSWER AFTER (AND OUTSIDE!) THIS BLOCKQUOTE.

According to the plot the higher the return, the higher the risk we have to bear. This is most certainly in line with market theory. We can also see that Tesla has by far the highest return, but also an accordingly high amount of risk involved (one never knows what Elon Musk might tweet next). To support our point in the previous questions, is is also clearly visible that ANF holds an unjustifiable amount of risk given the expected return. An investment in that stock would therefore prove rather questionable.

# On your own: Spotify

```{r, download_spotify_data}
# Download and assign spotifyr data to variable
spotify_songs <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv')


```

The data dictionary can be found below

| **variable**             | **class** | **description**                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|------------------|------------------|-------------------------------------|
| track_id                 | character | Song unique ID                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| track_name               | character | Song Name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| track_artist             | character | Song Artist                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| track_popularity         | double    | Song Popularity (0-100) where higher is better                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| track_album_id           | character | Album unique ID                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| track_album_name         | character | Song album name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| track_album_release_date | character | Date when album released                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
| playlist_name            | character | Name of playlist                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| playlist_id              | character | Playlist ID                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| playlist_genre           | character | Playlist genre                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| playlist_subgenre        | character | Playlist subgenre                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| danceability             | double    | Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.                                                                                                                                                                                                                                                                       |
| energy                   | double    | Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.                                                                                                                          |
| key                      | double    | The estimated overall key of the track. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1.                                                                                                                                                                                                                                                                                                                            |
| loudness                 | double    | The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.                                                                                                                                                                                       |
| mode                     | double    | Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.                                                                                                                                                                                                                                                                                                                                                    |
| speechiness              | double    | Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks. |
| acousticness             | double    | A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.                                                                                                                                                                                                                                                                                                                                                                                       |
| instrumentalness         | double    | Predicts whether a track contains no vocals. "Ooh" and "aah" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly "vocal". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.                                                                                                                 |
| liveness                 | double    | Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.                                                                                                                                                                                                                                                                                            |
| valence                  | double    | A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).                                                                                                                                                                                                                                                                  |
| tempo                    | double    | The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.                                                                                                                                                                                                                                                                                                                         |
| duration_ms              | double    | Duration of song in milliseconds                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |

Produce a one-page summary describing this dataset.

```{r, skim_spotifyr_data}
# Skim the spotifyr data
skimr::skim(spotify_songs)

```

The data analysed is provided as part of the spotifyr package, created by Charlie Thompson, Josiah Parry, Donal Phipps and Tom Wolff. The data set is a selected collection of songs found on the Spotify platform. Descriptive data is provided for each of the songs, ranging from generic information such as the name of the artist to more detailed analysis, for example the tempo of the track. While we can expect data such as the name of the track to be factual observations, variables such as energy or acousticness are most likely generated through an algorithm that labels the songs according to certain parameters. This means we can expect a certain margin of error in the assignments.

It makes sense to first look at the popularity_index of the songs listed in the dataset, as we can identify several concerns regarding the reliability of that data. A quick glimpse at the first couple of rows lets us deduct that several songs are repeated. This can be due to several reasons:

-   The same song from the same album is repeated from different playlists
-   The same song is repeated from different albums
-   The song was remastered or exists as an extended version

As the popularity_index is listed according to the track_id, there are no discrepancies between two copies of a song with the same track_id, even if listed from different playlists. While it make sense to remove these duplicates, it does not seem to significantly affect the distribution of values. However, when the same song is taken from different albums, the track_id and thus the popularity_index varies. An example would be Eminem´s "'Till I collapse", where one track has a popularity_index of 16 and the other 83. Both listed versions are from the album "Curtain Call", which is in fact uploaded twice on Spotify. It can be argued that it makes sense to only keep the highest rated version of the song, but we can expect the true popularity of the song to be higher if all the listeners of the less popular version were added to the more popular version. While this adjustment also does not significantly alter the distribution, it allows us to better judge the true popularity of individual songs. It should also be noted that since not all versions of a song might be listed on the dataset, we cannot safely determine the popularity of individual songs or artists as a whole. The Kiss song "Almost Human" from the album "Ikons" is listed in the dataset with a popularity of 0. By visiting the website [musicstax](musicstax.com), we can see that the same song from the album "Love Gun" enjoys a much higher popularity, but is not listed in the dataset. As for songs with extended or remastered versions, keeping both versions seems reasonable. In fact, it would be interesting to analyse the impact of releasing a remastered version of a song on its popularity. For this, a more complete dataset would be useful to properly determine a correlation.

As we graph the data on a histogram, we see that the popularity_index generally follows a normal distribution. This is to be expected, as the popularity_index is calculated based on factors such as stream, save and share count **relative** to other artists. The exception is the very high number of songs with a popularity_index of 0. Whether this is due to these songs being little to non-listened to duplicates or songs from lesser known artists is not discernible. In case of the latter, it is a good indicator of the competitiveness in the music industry, where many songs or artists never gain traction with their work. The spike at a value of 50 is also rather curious and should be investigated further.

```{r, investigate_spotifyr_popularity_index}

# creating a histogram to observe the distribution (entire dataset)

spotify_songs %>% 
  ggplot(aes(x = track_popularity)) + 
  geom_histogram(bins = 100) +
  theme_bw() +
  labs(title = "Distribution of songs by track_popularity",x="Track Popularity",y="Count")

# Remove song duplicates

unique_spotify_songs <- spotify_songs %>% 
  group_by(track_name,track_artist) %>% 
  summarize(max_track_popularity = max(track_popularity))

# creating a histogram to observe the distribution (dataset without duplicates)

unique_spotify_songs %>% 
  ggplot(aes(x = max_track_popularity)) + 
  geom_histogram(bins = 100) +
  theme_bw() +
  labs(title = "Distribution of songs by maximum track_popularity without duplicates",x="Track Popularity",y="Count")
```

Further interesting insights can be drawn when looking at the audio features of tracks in the data set. They allow us to gauge whether the majority of songs are, for example, rather energetic and can be used to determine if certain characteristics are correlated with the success of a song. By first inspecting the summary statistics of the audio features, we can already make predictions about the expected distributions. Depending on the value of the mean relative to the median, we can expect the distribution to be either normally distributed, left- or right-skewed. In our case, this principal is more applicable for some audio features than for others. Mode is either labelled 0 or 1, so with only data on the extremes of the x axis, we will not see a normal distribution around the mean. In fact, the mean rather gives us a ratio of minor to major scale songs. For valence however, the mean and median are almost exactly the same, so we can assert a high likelihood of a normal distribution (confirmed in graphing the data). Overall, the summary statistics suggest that most audio features are either left- or right-skewed, both with long and short tails.

When we look at the graphs of the distribution of audio features, there are some curious events to notice. First of all, we can see a large number of outliers for loudness with low dB. While the low dB seems reasonable for tracks like "Peaceful Forest" by "The Sleep Specialist", rock songs can also be found among the more quiet outliers. On the other end of the spectrum, we find fewer and less extreme outliers. Neverthless, the name "Raw Power" seems to be a fitting for the loudest tracks. As for the distribution of tempo, there is a spike at around 120-130. After a little bit of research, it turns out that an [analysis](https://medium.com/@Spotify/groove-is-in-the-heart-matching-beats-per-minute-to-heart-rate-271a79b7f96a) conducted by Spotify in 2016 revealed similar results. Apparently, this specific BPM seems to be a popular standard in the music industry. Last but not least, valence deserves a mention as being closest to a normal distribution. It seems reasonable that most songs would on average be neither too negative or positive in nature. Of course there are the tracks at the extremes, providing music to both people with heartbreak and those that have just graduated. Personally, we can attest to the reliability of the metric, as "Low Rider" by "War" has never failed to brighten the mood.

```{r, investigate_spotify_audio_features_distribution}

# Look at the summary statistics of the data set

summary(spotify_songs)

# Select Spotify_song descriptors from data

spotify_songs_descriptors <- spotify_songs %>% 
  select(danceability:duration_ms)

# Pivot Spotify song descriptor data

spotify_songs_descriptors_pivot <- spotify_songs_descriptors %>% 
  pivot_longer(colnames(spotify_songs_descriptors))

# Plot distribution of Spotify song descriptors

spotify_songs_descriptors_pivot %>% 
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_wrap(~ name, scales = "free") +
  theme_bw() +
  labs(title="Distributions of audio features",subtitle = "Faceted histogram of audio features",x = "Value", y = "Number of Observations")

# Create boxplot for loudness to spot outliers
spotify_songs %>% 
  ggplot(aes(x = loudness)) +
  geom_boxplot() +
  labs(title="Loudness has several outliers below the median volume",subtitle = "Boxplot of loudness audio feature",x = "Loudness")+
  theme_bw()
  
```

As with any kind of data analysis, it is interesting to determine relationships in the data. A simple correlation matrix lets us see whether certain audio features impact track_popularity or each other. First of all, we do not seem to have any significant correlation between audio features and track_popularity. This is good news, as it implies that artists can take complete liberty in the songs they produce, without negatively affecting their chance of success. Nevertheless, when we look at the average popularity by subgenre, we can observe certain subgenres like **hip hop** or **post-teen pop** to be more popular (this is based on the assumptions that the songs are correctly allocated to the respective playlist, hence playlist subgenre = song subgenre).

Looking at relationships between audio features offers a different picture. Energy is related to loudness, which seems perfectly reasonable. This is also in line with the negative correlation between acousticness and energy. Most energy inducing tracks feature mostly electronic sounds, such as in rock or EDM music. Meanwhile, most of the other audio features seem to be unrelated to each other, implying that tracks generally come in all shapes and sizes. Thus, a musician can freely choose to record music in major or minor keys, without impacting the danceability of popularity of his or her work.

```{r, calculate_spotifyr_correlations}
# Determine the correlation between audio features and popularity_index

spotify_songs %>% 
  select(track_popularity,danceability:duration_ms) %>% 
  cor()

# Determine average popularity_index and count by subgenre

spotify_songs %>% 
  group_by(playlist_subgenre) %>% 
  summarize(average_track_popularity = mean(track_popularity), count_of_subgenre = count(playlist_subgenre))

# Determine effect of mode on danceability and track_popularity

spotify_songs %>% 
  group_by(mode) %>% 
  summarize(average_track_popularity = mean(track_popularity), average_danceability = mean(danceability))

```

# Challenge 1: Replicating a chart

The purpose of this exercise is to reproduce a plot using your `dplyr` and `ggplot2` skills. It builds on exercise 1, the San Francisco rentals data.

You have to create a graph that calculates the cumulative % change for 0-, 1-1, and 2-bed flats between 2000 and 2018 for the top twelve cities in Bay Area, by number of ads that appeared in Craigslist.

```{r challenge1, out.width="100%"}

rent %>% 
  filter(beds %in% c(0,1,2),
         city %in% top_cities$city) %>% 
  # Fielter out the right city with right number of beds
  group_by(city,beds,year) %>% 
  arrange(year) %>% 
  summarize(median_price=median(price))%>% 
  # calculate the median price in each year in each group
  ungroup %>% 
  group_by(city,beds) %>% 
  mutate(initial_price=dplyr::first(na.omit(median_price))) %>% 
  # Find the initial value (price in 2000) for each group(city:beds)
  mutate(cumulative_change=median_price/initial_price) %>%
  # cumulative change = current price / initial price
  ggplot(aes(x=year,y=cumulative_change,color=city))+
  geom_line()+
  facet_grid(beds~city,scales = "free_y")+ # facet by beds and city in grid
  scale_y_continuous(labels=scales::percent)+ 
  # change the y-axis lable into percentage
  theme_bw()+
  theme(axis.text.x = element_text(vjust = 0.5, hjust=1,angle =90))+
  theme(plot.title.position = "plot")+
  labs(title = "Cumulative  % change in 0,1,2-beds rentals in Bay Area",subtitle="2000-2018",x=NULL,y=NULL)+
  theme(legend.position  = "none")



```

# Challenge 2: 2016 California Contributors plots

As discussed in class, I would like you to reproduce the plot that shows the top ten cities in highest amounts raised in political contributions in California during the 2016 US Presidential election.

```{r, load_CA_data, warnings= FALSE, message=FALSE, fig.height = 4}
# Loading the data frames and assigning them to variables
CA_contributors_2016 <- vroom::vroom(here::here("data","CA_contributors_2016.csv"))
zip_code_database <- vroom::vroom(here::here("data","zip_code_database.csv"))

# Transforming data type of zip_code_database to match CA_contributors_2016
zip_code_database$zip <- as.double(zip_code_database$zip)

# Join data frames and assign to variable
joined_CA_contributors_2016 <- left_join(CA_contributors_2016,zip_code_database,by = "zip")

# Group and summarize data for graph
top_contributing_cities <- joined_CA_contributors_2016 %>% 
  group_by(cand_nm,primary_city) %>% 
  summarize(amount_raised = sum(contb_receipt_amt))

# Find top 10 cities per candidate
top_contributing_cities %>%
  group_by(cand_nm) %>% 
  top_n(n=10) %>% 
  ungroup %>%
  filter(cand_nm %in% c("Clinton, Hillary Rodham","Trump, Donald J.")) %>% 
  mutate(cand_nm = as.factor(cand_nm), primary_city = tidytext::reorder_within(x = primary_city, by = amount_raised, within = cand_nm)) %>% 
  ggplot(aes(x = primary_city,y = amount_raised, fill = cand_nm)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~cand_nm, scales ="free") +
  coord_flip() +
  tidytext::scale_x_reordered() +
  scale_y_continuous(labels = scales::dollar_format()) +
  scale_fill_manual(values = c("blue","red")) +
  theme_bw() + 
  labs(y = "Amount raised", x = NULL, title = "Where did candidates raise most money?")
```

